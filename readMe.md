## Overview 
Developed and optimized a neural network to predict heart disease, incorporating several advanced techniques for improved performance. 
I used effective weight initialization methods to ensure faster convergence and mitigate the risk of vanishing or exploding gradients. 
To prevent overfitting, I implemented L2 regularization, which adds a penalty term to the loss function and discourages large weights. 
Mini-batch gradient descent was employed to update the network's weights efficiently by computing the gradient on small, random subsets 
of the training data, balancing stability and speed. Additionally, I applied gradient descent optimization with momentum, which uses past 
gradients to smooth out updates, helping the network navigate the loss landscape more effectively and avoid local minima.

## Details
For graphs and detailed explanations on insights and their sources please see `Neural_Network_Project.ipynb` where the neural network is explained step-by-step. 